业务理解：
快手数据平台部-消费数据组-消费策略方向
   1.基于消费的数据资产，为策略算法提供数据分析和离线侧数据基建服务

  以策略实验为主，为reco提供数据服务与数据分析服务，DE➕DA的角色，助力策略的每一个idea的产生到最终实验推全
  项目背景：（全人群纠偏）
    推荐不准，本质上是分发未能体现用户的兴趣
    因为对用户分发前会预测用户的兴趣，会存在强势人群的兴趣带偏弱势人群，大盘整体的兴趣带偏强势人群等问题
    去看人群对什么样的视频感兴趣，尽可能纠正现有的分发偏差
    对用户的属性划分人群，引入pxtr，cnt等信号对相应人群进行分发调控，优化人群的使用体验，提升大盘人均使用时长

  项目过程：
    1.算法提出idea，人群标签*视频时长，分析人群对不同视频时长的视频是否有偏好，进行分析，给出结论（怎么分析的？）
    2.基于结论为线上实验做数据基建，过程中自己探查取数口径（怎么看的口径？）
    3.数据分析阶段会为策略提供有效信息（可能有收益的标签，取数方案，取数口径）
    4.数据基建后为业务提供有效信息（取数口径，代码优化，代码review等）
    5.提供相应的监控看版，例如大盘AA监控等，保证产品稳定性

  项目困难点：
    1.策略理解：策略相关的各种名词，（线上实验，先验后验，启发式纠偏，精排粗排等），一个实验产生到推全经历的过程等，以及之前的策略方向是怎样的
      解决方法：翻看部门的文档，之前的lr实验，以及之前做这个方向的DE的任务是怎样的，梳理链路和方法论
    2.业务理解：理解消费策略，每一个指标的含义，每一个标签限制的原因（各级流量的限制，影响实验的正向）
      解决方法：翻看别人代码的逻辑，翻看部门白皮书，自己总结经验，问mentor，问同事，问ai
    3.数仓理解：建表时使用哪些指标，指标的覆盖率，时效性，复用性
      解决方法：指标的准确性与标签时效性：进行数据探查，寻找更好的资产（不能提前和业务说明原因）
              复用性：与业务交流，看他们之后的工作方向（比如看的标签是作者侧的，视频侧的，会在底表留出aid，pid方便后续维度的补充）
    4.代码优化：有些策略分析场景，需要看潮汐数据（小时级，周中周末）需要保证产出的时效性
      解决方法： 1.尽可能保留业务自身的兜底逻辑（存在多次扫描的情况）代码上的优化
              2.优化参数：开启map join，提高堆内，堆外内存大小，提高执行器的个数
              3.使用产出更早的资产（与原口经探查diff，通知业务可能存在的问题）
              4.与业务沟通，简化逻辑
    5.与业务的交流与自身的成长：
      从确定性的，滞后的，远离业务的DE的工作，过渡到承接分析与探查口径的DA的工作+DE的工作，如何使自己的分析逻辑性更好，分析的工具如何使用
      解决办法：分析的逻辑性是层层相关的，前一步的小结论引导者后一步的分析方向；数据呈现（分析的工具）面向应用的学习，学会了tableau等
      
  项目收益：
    3个月
    1.策略收益：LR：助力人群纠偏方向6个实验推全
              时长收益：大盘人均的app时常累计+1.6%
    2.数仓收益：1.负责属性人群方向的数据资产，构建hive表10张
              2.每个数据资产都有文档说明，底表复用性强，数据产出稳定，准确
              3.设置合理的生命周期，数据表存储合理，任务执行占用资源合理
    3.数据分析收益：1.提供了11篇分析文档，被reco认可，分析结果再多个实验推全doc，年终述职doc，老板的文档中使用
                2.学会了分析的思路，尝试了很多分析的工具

  项目收获：
    1.业务思维：
    长期从事DE的工作，会缺少部分业务思维，因为分析相关的工作，所以工作中的进展会最先获得
    2.数仓理解：
    因为数仓任务资源，存储资源的要求，其次在建表过程中会模仿其他表去学习优化的代码写法，
    促使我思考每一张表的复用性，后续的改造，产出的实效性的问题
    3.分析思路：

    4.跨部门沟通：
    这部分的算法大佬非常的专业，带我的mentor也很负责信任，虽然在工作的初期遇到了很多问题
    但是每一次遇到问题都是面对面的沟通，有问题及时解决，帮助我成长了很多

  项目做的好的地方：
    1.工作本身：及时的交付，每个需求都认真对待，写清晰的文档，字段，代码，口径
    2.主动学习：学习新技术，了解新的业务
    3.主动沟通，承认工作中的不足，及时的改正

  项目做的不好的地方：
    1.沟通的时候，逻辑还是不够清晰，思维跳脱，
    解决方法：会议前理清逻辑，正在做什么+那里遇到了卡点+提出疑问，把对方当成小白，不要自己脑中头脑风暴
    2.


  项目中可以提高的地方：


携程
  携程-火车票研发部-数仓组
    针对携程下所有业务线的火车票相关的业务，提供数据服务
  项目背景：
  ab实验指标产出实效性治理
    （1）产出实效性不稳定，影响业务看数
    （2）新增指标开发成本高：回溯成本，运行资源成本
    （3）产出资源消耗大
  项目过程：
    （1）指标梳理与盘点：
        聚焦重点业务域：优先梳理交易域（如订单量、支付率、取消率、成功率）和收益域（如成本、支付金额）等核心业务指标；
        明确指标归属关系：识别各指标对应的具体业务过程（如提交、支付、取消、出票），厘清业务上下文。
    （2）指标口径统一与治理：
        分析订阅使用情况：提取各指标的订阅与调用数据，评估实际使用价值；
        开展跨业务线对齐：联合各业务线负责人及数据分析团队，确认指标定义与计算逻辑的一致性；
        制定治理决策：基于对齐结果，明确需下线、合并或保留的指标清单，并推进落地执行。
    （3）模型架构优化与重构：
        实施分层设计：依据“粒度 + 周期 + 数据域 + 业务线”原则，对原有指标池进行合理拆分；
        沉淀公共逻辑：将同业务线共性的处理逻辑下沉至DWD或DWS层，减少重复计算；
        整合数据资产：按业务线整合现有表结构，合并冗余表，形成边界清晰、易于维护的数据集。
    （4）数据链路性能优化：
        上游表治理：针对影响产出时效的关键上游表，开展优化工作，包括代码逻辑精简、切换高效数据源、构建中间缓存表等；
        作业性能调优：对核心任务进行性能剖析，优化SQL语句及计算逻辑，提升执行效率。
  项目困难： 
    （1）指标逻辑复杂，难以拆分，伴随着业务理解不够深刻，对于过滤和兜底不了解原因
    解决方法：多读业务文档，问mentor和业务大佬们
    （2）跨部门的沟通：确认指标口径和推动指标下线的过程中，与业务沟通
  项目收益：
    （1）提升指标产出实效性：T+1的产出时效，保证指标90%在2点前产出
    （2）任务资源:
        运行资源：
        存储资源：
  项目收获：
    （1）对任务治理的深入理解：
    （2）跨部门的沟通：

  项目中做的不好的地方：

任务治理的思路：
  （1）SQL优化：
    减少分区扫描，减少读取：了解表的分区，主键，明确写出枚举值（过滤条件尽量写在where中-列裁剪，而不是计算时-行裁剪），一些大日志文件方便读取会有特定的UDF
    理解业务逻辑：减少表的读取次数，如果对同一张表多次读取，可以提取相同的逻辑，建立中间表，视图（计算逻辑简单）等
    换表：越明细的大表肯定跑的更慢，在满足业务要求的基础上，选取粒度小，表小的表（各个业务线的负责人询问资产）
    去重：distinct的开销较大，尤其是大表，可以用group by代替（count distinct默认开启一个reduce）
      （有时表本身粒度契合，或者限制条件后，需要的粒度数据已经是符合要求了，再次去重就很多余）
    排序：使用min max代替row_number()代替(使用row_number时对数据在reduce阶段进行分组排序后再取一条记录
        使用min or max排序在map端，并且shuffle时只取一条记录)
        优化前：
          select    device_id 
                  ,city_name 
                  ,street_name 
            
          from   (
            select   device_id
                    ,city_name 
                    ,street_name 
                    ,row_number() over (partition by device_id order by time) as rn 
            from    t1 
          ) t2
          where    rn = 1
        优化后：
          select    device_id 
                   ,first_info.col2 as city_name 
                   ,first_info.col3 as street_name
          from   (
            select   device_id
                    ,min(struct(time,city_name,street_name)) as first_info
            from    t1 
            group by device_id 
          ) t2
          如果order by阶段有字段重复，排序结果并不稳定，加入随机数，模拟row_number在遇到相同字段时的随机排序
          min（time，rand(1),ip）
          适用场景：1.分组中重复率高；2.只取分组中的首末3.数据量大

  （2）参数优化：
      1.maptask的调整：
        ## map task 动态切分大小
        spark kwai.sql.dynamic.maxPartitionBytes = 1073741824（1G）
              文件过小合并到一个里面，文件过大进行拆分

        ## map task 动态切分个数
        spark kwai.sql.dynamic.maxPartitionCount = 10000
              如果切分的文件过多，会自动按倍数增大单task的大小，减小maptask的数量      
        优化案例：
            1.maptask数量特别多，执行时间长，但是看单个task执行的时间非常小，时间耗在task等待上
              做法：
                  增加分片大小，设置maptask个数
            2.查看触发动态分片调整功能，在日志中搜索estimate
            3.maptask分片少，但是耗时长
              做法：
                  减小单个分片大小（增加task个数）and 加大并发（加大map并发）
                  spark.executor.cores = 4 --增加核的数量
                  spark.executor.memory = 10g --增加内存
                  spark.dynamicAllocation.maxExecutors = --增加申请执行器最大个数
      2.reducetask的调整：
        ## reduce task处理数据量的大小
        spark.sql.adaptive.shuffle.targetPostShuffleInputSize = 268435456(256M)
        mr中的reduce数量是作业提交时根据数据量估算的，所以reduce的实际处理数据量与真实的偏差很大
        spark开启了AQE功能（根据执行信息动态调整执行计划）根据map task的输出计算reduce数量

        ## 单个stage生成的reduce最大个数
        spark.sql.adaptive.maxNumPostShufflePartitions = 5000
        参考：shuffle <= 200GB , 500
             shuffle [200GB,800GB] , 1000
             shuffle [800GB,3000GB] , 3000
             shuffle >= 200GB , 5000
        优化案例:
            1.shuffle平均执行时间长，并且task数量少
              做法：减少每个reduce处理的数据量，加大reduce并发（如果单个reduce处理的数据量大，说明是数据倾斜不能这么解决）
            2.shuffle数据量小，reduce task平均耗时短
              做法：减小单个stage生成的reduce最大个数
            3.多个union会被合并到一个stage中，每个union的reducetask加和会导致该stage reduce数量特别大（查看执行计划图）
              做法：降低单个stage生成的reduce最大个数
                 spark.sql.adaptive.maxNumPostShufflePartitions = 5000
      3.小文件问题的优化：
        导致的问题：HDFS的namenode元数据过多；下游任务的读取性能
        ## 小文件合并
        spark.sql.mergeFile.enabled = true 
        ## 小文件合并目标大小
        spark.sql.mergeFile.target.fileSize = 536870912(512M)
        ## 文件数阙值，触发小文件合并
        spark.sql.mergeFile.minFileCount.threshold = 50 
        ## 合并小文件时，单个task处理的最大文件数，避免小文件合并阶段耗时较长
        spark.sql.mergeFile.maxFileCount.perPartition = 200 
        优化案例：
            1.报错：生成的临时小文件过多（文件个数 = 发生shuffle后的stage的task数（reducetask）*分区的数量
              做法：减少无用的子分区；减少输出stage的task的数量（reduce task的数量）
                  # 1.控制 shuffle 分区数
                  spark.sql.shuffle.partitions = 100
                  # 2.AQE 自动合并shuffle分区
                  spark.sql.adaptive.enabled = true
                  spark.sql.adaptive.coalescePartitions.enabled = true
                  spark.sql.adaptive.advisoryPartitionSizeInBytes = 268435456   #每个分区处理的数据量
                  # 3.如果上个阶段是scan，减少maptask数量
                  spark kwai.sql.dynamic.maxPartitionCount = 10000
                  # 4.如果是shuffle，限制reduce数量
                  spark.sql.adaptive.maxNumPostShufflePartitions = 5000
            2.小文件合并耗时较长，说明需要合并的小文件过多
              做法：减少单个task处理的最大文件数，从而增大并发
                  ## 合并小文件时，单个task处理的最大文件数，避免小文件合并阶段耗时较长
                  spark.sql.mergeFile.maxFileCount.perPartition = 200 

      4.executor资源分配的优化：spark最初是在作业开始阶段申请固定executor，但容易导致资源浪费
        ## 资源动态分配
        spark.dynamicAllocation.enabled = true 
        ## 动态资源分配的最少executor个数
        spark.dynamicAllocation.minExecutors = 1
        ## 动态资源分配的最大executor个数
        spark.dynamicAllocation.maxExecutors = 1600 
      5.增大并发：一个executor是一个JVM进程，默认一个task占一个core
        ## 单个executor申请的cpu资源量及task并发度
          park.executor.cores = 5
      6.driver不足的优化
        ## driver内存堆的大小
        spark.driver.memory = 12g 
        ## driver堆外内存的大小 
        spark.driver.memoryOverhead = 3072 
        ## driver保存的序列化结果的大小，driver内存中缓存的那些“已序列化的 Task 描述、RDD/Stage 元数据、广播引用等对象所占的总内存大小
        spark.driver.maxResultsize = 20g 
          优化案例：
              1.driver内存不足：由于broadcast数据量过大导致的
                做法：加大driver内存；调整broadcast阙值解决
                spark.driver.memory = 15g 
                spark.sql.autoBroadcastJoinThreshold = 
              2.driver内存不足可能导致executor频繁失败
                做法：内存使用率较高or内存溢出-》适当增加driver内存
              3.driver保存的序列化结果超过阙值
                做法：加大序列化内存 or 调整分片
                spark.driver.maxResultsize = 20g （一般大于driver大小）
      7.broadcast（广播）优化大小表join：
          将小表的数据在driver端序列化后，存放在blockmanager，然后executor端再从driver端拉取到自己的节点上
          broadcast阶段在spark ui界面上可以看到
          ## 触发广播的大小
          spark.sql.autoBroadcastJoinThreshold = 52428800(50M) -》 -1为关闭广播
          优化案例：
              1.突然出现了数据倾斜，看之前是否有broadcast现在没有
                做法：提高broadcast的阙值
              2.broadcast导致driver不足：由于阙值设置过大
                做法：调大driver内存，降低broadcast的阙值
      8.自适应查询（AQE）
          什么是AQE？自适应查询
          为什么用AQE？
            1.reduce的并发度问题：对于复杂查询，会生成很多shuffle stage，每个stage都有不同的shuffle数据量，相同的reduce并发度不合适
            2.执行计划并非最优，在运行过程中不能自己调整
          AQE能做什么？
            1.针对不同的stage，根据shuffle的大小，动态生成reducetask的个数
            2.根据运行情况，可以将shuffle SortMergeJoin降级为BroadcastHashJoin
          ## AQE开启
          spark.sql.adaptive.enabled = true 

          
          
                
          




  （3）数据倾斜问题：
      场景一：

      场景二：

    



  
